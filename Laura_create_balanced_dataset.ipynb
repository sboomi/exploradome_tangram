{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Laura_create_balanced_dataset.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sboomi/exploradome_tangram/blob/master/Laura_create_balanced_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TBFXQGKYUc4X"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "1z4xy2gTUc4a",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KwQtSOz0VrVX"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/images/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gN7G9GFmVrVY"
      },
      "source": [
        "This tutorial shows how to classify cats or dogs from images. It builds an image classifier using a `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`. You will get some practical experience and develop intuition for the following concepts:\n",
        "\n",
        "* Building _data input pipelines_ using the `tf.keras.preprocessing.image.ImageDataGenerator` class to efficiently work with data on disk to use with the model.\n",
        "* _Overfitting_ —How to identify and prevent it.\n",
        "* _Data augmentation_ and _dropout_ —Key techniques to fight overfitting in computer vision tasks to incorporate into the data pipeline and image classifier model.\n",
        "\n",
        "This tutorial follows a basic machine learning workflow:\n",
        "\n",
        "1. Examine and understand data\n",
        "2. Build an input pipeline\n",
        "3. Build the model\n",
        "4. Train the model\n",
        "5. Test the model\n",
        "6. Improve the model and repeat the process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VddxeYBEVrVZ"
      },
      "source": [
        "Let's start by importing the required packages. The `os` package is used to read files and directory structure, NumPy is used to convert python list to numpy array and to perform required matrix operations and `matplotlib.pyplot` to plot the graph and display images in the training and validation data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jlchl4x2VrVg"
      },
      "source": [
        "Import Tensorflow and the Keras classes needed to construct our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nmMfiSBcXZST",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L1WtoaOHVrVh",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DPHx8-t-VrVo"
      },
      "source": [
        "Begin by downloading the dataset. This tutorial uses a filtered version of <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Dogs vs Cats</a> dataset from Kaggle. Download the archive version of the dataset and store it in the \"/tmp/\" directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bClu_O_Y22wQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VpmywIlsVrVx"
      },
      "source": [
        "After extracting its contents, assign variables with the proper file path for the training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sRucI3QqVrVy",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "PATH = '/content/drive/My Drive/data/'\n",
        "train_dir = os.path.join(PATH, 'train_full')\n",
        "validation_dir = os.path.join(PATH, 'test_full')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZdrHHTy2VrV3"
      },
      "source": [
        "### Understand the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LblUYjl-VrV3"
      },
      "source": [
        "Let's look at how many cats and dogs images are in the training and validation directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vc4u8e9hVrV4",
        "colab": {}
      },
      "source": [
        "num_tr = len(os.listdir(train_dir))\n",
        "num_val = len(os.listdir(validation_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRGRvlininjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(os.listdir(train_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl8yMKXMihza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7Dgi-5KlGNb",
        "colab_type": "text"
      },
      "source": [
        "We can verify with the preceding output that we have the same number of images for each category. Let’s now build our smaller dataset, so that we have 140 images for training of each categories, and 28 images for our test dataset of each categories (20% of train dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydrzbj9tWDaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of img for each categories, and create list of all img for each categories\n",
        "\n",
        "string_train = []\n",
        "\n",
        "for i in os.listdir(train_dir):\n",
        "  print(train_dir+\"/\"+i)\n",
        "  print(len(os.listdir(train_dir+\"/\"+i)))\n",
        "  string = os.listdir(train_dir+\"/\"+i)\n",
        "  string_train.append(string)\n",
        "  print(string_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tl__1YXoETp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of img for each categories, and create list of all img for each categories\n",
        "\n",
        "string_valid = []\n",
        "\n",
        "for i in os.listdir(validation_dir):\n",
        "  print(validation_dir+\"/\"+i)\n",
        "  print(len(os.listdir(validation_dir+\"/\"+i)))\n",
        "  string = os.listdir(validation_dir+\"/\"+i)\n",
        "  string_valid.append(string)\n",
        "  print(string_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ0FbC_IQKuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(string_train)\n",
        "string_train[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CxAHDsXO2GE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split random dataset\n",
        "\n",
        "import random\n",
        "\n",
        "def split_train_balanced(string, nb):\n",
        "  class_train_balanced = []\n",
        "  for i in range(len(string)):\n",
        "    class_train = random.sample(string[i], k=nb)\n",
        "    class_train_balanced.append(class_train)\n",
        "  return class_train_balanced\n",
        "\n",
        "#train_balanced = split_train_balanced(string_train, nb=140)\n",
        "#nb=140, because maison =140 images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8dkJyDOY5Rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_balanced)\n",
        "train_balanced[5]\n",
        "len(train_balanced)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqBPt1eeb5SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_class = os.listdir(train_dir)\n",
        "list_class[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9N878Z8Uf4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy img of dataset to new folder\n",
        "\n",
        "import shutil\n",
        "\n",
        "source_train= train_dir \n",
        "source_test= validation_dir\n",
        "dest_train=\"/content/drive/My Drive/data/train_balanced/\"\n",
        "dest_test=\"/content/drive/My Drive/data/test_balanced/\"\n",
        " \n",
        "\n",
        "def copy_file(source,dest,data_balanced):\n",
        "    for i in range(len(data_balanced)):\n",
        "      for j in range(len(data_balanced[i])):\n",
        "        #print(train_balanced[i])\n",
        "        # Copy file to another directory\n",
        "        #print(source +\"/\"+ list_class[i] +\"/\"+ train_balanced[i][j])\n",
        "        newPath = shutil.copy(source +\"/\"+ list_class[i] +\"/\"+ data_balanced[i][j], dest + list_class[i])\n",
        "        print(\"Path of copied file : \", newPath)     \n",
        "\n",
        "train_balanced_img = copy_file(source_train,dest_train, train_balanced)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q545At1ssCCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in os.listdir(\"/content/drive/My Drive/data/train_balanced\"):\n",
        "  print(\"/content/drive/My Drive/data/train_balanced\"+\"/\"+i)\n",
        "  print(len(os.listdir(\"/content/drive/My Drive/data/train_balanced\"+\"/\"+i))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03xsr8I0lJVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_balanced = split_train_balanced(string_test, nb=28)\n",
        "#nb=28 for 20% of 140 img\n",
        "test_balanced_img = copy_file(source_test,dest_test,test_balanced)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k09ScU7QnO_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in os.listdir(\"/content/drive/My Drive/data/test_balanced\"):\n",
        "  print(\"/content/drive/My Drive/data/test_balanced\"+\"/\"+i)\n",
        "  print(len(os.listdir(\"/content/drive/My Drive/data/test_balanced\"+\"/\"+i))) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}